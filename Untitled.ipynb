{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "import efficientnet_builder\n",
    "import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_data():\n",
    "  path = './../main/'\n",
    "  train = pd.read_csv(path+'CheXpert-v1.0-small/train.csv')\n",
    "  valid = pd.read_csv(path+'CheXpert-v1.0-small/valid.csv')\n",
    "  \n",
    "  train['validation'] = False\n",
    "  valid['validation'] = True\n",
    "  df = pd.concat([train, valid])\n",
    "  \n",
    "  columns = ['Path', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'validation']\n",
    "  df = df[columns]\n",
    "  \n",
    "  for feature in ['Atelectasis', 'Edema']:\n",
    "      df[feature] = df[feature].apply(lambda x: 1 if x==-1 else x)\n",
    "  \n",
    "  for feature in ['Cardiomegaly', 'Consolidation', 'Pleural Effusion']:\n",
    "      df[feature] = df[feature].apply(lambda x: 0 if x==-1 else x)\n",
    "  df.fillna(0, inplace=True)\n",
    "  \n",
    "  train = df[~df.validation][:500]\n",
    "  print(len(train))\n",
    "  train_files = train['Path'].tolist()\n",
    "  train_files = [path+fil for fil in train_files]\n",
    "  \n",
    "  columns = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "  train_labels = np.array(train[columns])\n",
    "  \n",
    "  valid = df[df.validation]#[:50]\n",
    "  print(len(valid))\n",
    "  valid_files = valid['Path'].tolist()\n",
    "  valid_files = [path+fil for fil in valid_files]\n",
    "  \n",
    "  columns = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "  valid_labels = np.array(valid[columns])  \n",
    "  return train_files, train_labels, valid_files, valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size 380\n"
     ]
    }
   ],
   "source": [
    "MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "\n",
    "\n",
    "model_name='efficientnet-b4'\n",
    "batch_size=32\n",
    "\"\"\"Initialize internal variables.\"\"\"\n",
    "model_name = model_name\n",
    "batch_size = batch_size\n",
    "num_classes = 1000\n",
    "# Model Scaling parameters\n",
    "_, _, image_size, _ = efficientnet_builder.efficientnet_params(\n",
    "      model_name)\n",
    "print('image_size', image_size)\n",
    "\n",
    "def restore_model(sess, ckpt_dir):\n",
    "  \"\"\"Restore variables from checkpoint dir.\"\"\"\n",
    "  checkpoint = tf.train.latest_checkpoint(ckpt_dir)\n",
    "  ema = tf.train.ExponentialMovingAverage(decay=0.9999)\n",
    "  ema_vars = tf.trainable_variables() + tf.get_collection('moving_vars')\n",
    "  for v in tf.global_variables():\n",
    "    if 'moving_mean' in v.name or 'moving_variance' in v.name:\n",
    "      ema_vars.append(v)\n",
    "  ema_vars = list(set(ema_vars))\n",
    "  var_dict = ema.variables_to_restore(ema_vars)\n",
    "  saver = tf.train.Saver(var_dict, max_to_keep=1)\n",
    "  saver.restore(sess, checkpoint)\n",
    "  return saver\n",
    "\n",
    "def build_model(features, is_training):\n",
    "  \"\"\"Build model with input features.\"\"\"\n",
    "  features -= tf.constant(MEAN_RGB, shape=[1, 1, 3], dtype=features.dtype)\n",
    "  features /= tf.constant(STDDEV_RGB, shape=[1, 1, 3], dtype=features.dtype)\n",
    "  out, _ = efficientnet_builder.build_model_base(\n",
    "      features, model_name, is_training)\n",
    "  return out\n",
    "\n",
    "def build_dataset(filenames, labels, is_training):\n",
    "  \"\"\"Build input dataset.\"\"\"\n",
    "  filenames = tf.constant(filenames)\n",
    "  labels = tf.constant(labels)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "  def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = preprocessing.preprocess_image(\n",
    "        image_string, is_training, image_size=image_size)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "  dataset = dataset.map(_parse_function)\n",
    "  dataset = dataset.batch(batch_size)#.repeat()\n",
    "  return dataset\n",
    "\n",
    "\n",
    "\n",
    "def _loss(x, y):\n",
    "  logits = tf.contrib.layers.fully_connected(x, 5, activation_fn=None)  \n",
    "  predicts = tf.math.sigmoid(logits, name = 'sigmoid_logits')\n",
    "  cross_entropy = tf.losses.sigmoid_cross_entropy(logits=logits,\n",
    "                                                  multi_class_labels=y)\n",
    "  weight_decay = 1e-5\n",
    "  loss = cross_entropy + weight_decay * tf.add_n(\n",
    "      [tf.nn.l2_loss(v) for v in tf.trainable_variables()\n",
    "       if 'batch_normalization' not in v.name])\n",
    "  return loss, predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
